<!DOCTYPE html>
<html>
<head>
  <title>Scalable Data Mining (CS60021)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 20px;
    }

    h1, h2, h3 {
      color: #007BFF;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
    }

    th, td {
      border: 1px solid #ccc;
      padding: 8px;
    }

    th {
      background-color: #007BFF;
      color: #fff;
    }

    th:first-child, td:first-child {
      min-width: 100px;
    }

    a {
      color: #007BFF;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <h1>Scalable Data Mining (CS60021)</h1>
  <p><strong>Instructor:</strong> Sourangshu Bhattacharya</p>
  <p><strong>Teaching Assistants:</strong> Kiran Purohit, Anurag Parvathgari</p>
  <p><strong>Class Schedule:</strong> Monday (8:00 - 9:55), Tuesday (12:00 - 12:55)</p>
  <p><strong>Classroom:</strong> CSE - 107</p>
  <p><strong>Last year course website:</strong> <a href="https://cse.iitkgp.ac.in/~sourangshu/coursefiles/cs60021_2022a.html">https://cse.iitkgp.ac.in/~sourangshu/coursefiles/cs60021_2022a.html</a></p>

  <h2>Announcements:</h2>
  <ul>
    <li>Assignment 1 is due next week (28th August). Check moodle.</li>
    <li>Class test 1 on 5th September.</li>
  </ul>
    
  <h2>Course Schedule:</h2>
  <table border="1">
    <tr>
      <th>Week</th>
      <th>Dates</th>
      <th>Topic / Activity</th>
      <th>Links / Material</th>
    </tr>
    <tr>
      <td>Week 0</td>
      <td>1/8</td>
      <td>Introduction</td>
      <td><a href="slides/intro.pdf">Slides</a></td>
    </tr>
    <tr>
      <td>Week 1</td>
      <td>7/8, 8/8</td>
      <td>Introduction to DM, ML, Stochastic gradient descent.</td>
      <td><a href="slides/01-ML-intro.pdf">Slides - Intro to ML</a>,
        <a href="slides/02-ML-optim.pdf">Slides - SGD + Acceleration</a>
      </td>
    </tr>
    <tr>
      <td>Week 2 + 3</td>
      <td>14/8, 21/8, 22/8</td>
      <td>SGD convergence rate, Pytorch</td>
      <td><a href="slides/02a-SGD-convergence.pdf">Slides - SGD Convergence</a>,
        <a href="slides/03-DL-framework.pdf">Slides - Pytorch</a>
      </td>
    </tr>
    <tr>
      <td>Week 4 </td>
      <td>28/8, 29/8</td>
      <td>Distributed Optimization, ADMM</td>
      <td><a href="slides/04-admm.pdf">Slides - ADMM</a>,
      </td>
    </tr>
    <tr>
      <td>Week 5 </td>
      <td>4/9, 5/9</td>
      <td>Map-reduce framework, Hadoop</td>
      <td><a href="slides/05-hadoop.pdf">Slides - Hadoop</a>,
      </td>
    </tr>
    <tr>
      <td>Week 6 </td>
      <td>11/9, 12/9</td>
      <td>Spark</td>
      <td><a href="slides/06-spark.pdf">Slides - Spark</a>,
      </td>
    </tr>
    <tr>
      <td>Week 7+8 </td>
      <td>3/10, 9/10, 10/10</td>
      <td>Locality Sensitive Hashing</td>
      <td><a href="slides/07-LSH.pdf">Slides - Shingling, Minhash, LSH, Gap - LSH</a>,
      <td><a href="slides/08-multi-probe-LSH.pdf">Multi-probe LSH</a>,
      </td>
    </tr>
    <tr>
      <td>Week 9 </td>
      <td>16/10, 17/10</td>
      <td>ANNS - HNSW</td>
      <td><a href="slides/09-HNSW.pdf">Slides - HNSW </a>
      </td>
    </tr>    
    <!-- Add more rows for other weeks as needed -->
  </table>
  
  <h2>Syllabus:</h2>
  <h3>Software paradigms:</h3>
  <ul>
    <li>Big Data Processing: Motivation and Fundamentals, Map-reduce framework, Functional programming, and Scala Programming using map-reduce paradigm, Example programs.</li>
    <li>Deep Learning Frameworks (Pytorch): Motivation, Computation graphs, Tensors, Autograd, Modules, Example programs.</li>
  </ul>

  <h3>Optimization and Machine learning algorithms:</h3>
  <ul>
    <li>Optimization algorithms: Stochastic gradient descent, Variance reduction, Momentum algorithms, ADAM.</li>
    <li>Algorithms for distributed optimization: Distributed stochastic gradient descent and related methods. ADMM and decomposition methods.</li>
    <li>(New) Federated Learning.</li>
  </ul>

  <h3>Algorithmic techniques:</h3>
  <ul>
    <li>Finding similar items: Shingles, Minhashing, Locality Sensitive Hashing families, FAISS.</li>
    <li>Stream processing: Motivation, Sampling, Bloom filtering, Count-based sketches: FM sketch, AMS sketch, Hash-based sketches: count sketch.</li>
    <li>Subset Selection Methods: Submodular Optimization, Sparse Approximation, Convex Optimisation.</li>
  </ul>

  <h2>References:</h2>
  <ol>
    <li>Mining of Massive Datasets. 2nd edition. - Jure Leskovec, Anand Rajaraman, Jeff Ullman. Cambridge University Press. <a href="http://www.mmds.org/">http://www.mmds.org/</a></li>
    <li>Tensorflow for Machine Intelligence: A hands-on introduction to learning algorithms. Sam Abrahams et al. Bleeding edge press.</li>
    <li>Hadoop: The Definitive Guide. Tom White. O'Reilly Press.</li>
    <li>Recent literature.</li>
  </ol>
</body>
</html>
